<!DOCTYPE html>

<html lang="en" data-content_root="../../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />



  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../../../_static/javascripts/modernizr.js"></script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXX"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'UA-XXXXX');
</script>
  
  
    <title>graphnet.models.gnn.dynedge &#8212; graphnet  documentation</title>

<style>
  dt:target {
    margin-top: 0;
    padding-top: 0;
  }


  /*
    .sig-prename {
     display: none;
  }
  */

  .py.class .sig-name,
  .py.function .sig-name,
  .py.method .sig-name,
  .py.exception .sig-name {
    color: #37474f;
    font-feature-settings: "kern";
    font-family: "Roboto Mono", "Courier New", Courier, monospace;
    font-weight: 700;
  }

  .py.class .sig-object,
  .py.function .sig-object,
  .py.method .sig-object,
  .py.exception .sig-object {
    padding: 1ex;
  }

  .py.class .sig-object,
  .py.function .sig-object,
  .py.exception .sig-object {
    border-top: 1px solid gray;
  }
  .py.method .sig-object {
    border-top: 1px solid lightgray;
  }

  .py.class .sig-object,
  .py.exception .sig-object {
    background: rgba(0,0,0,0.06);
  }
  .py.function .sig-object,
  .py.method .sig-object {
    background: rgba(0,0,0,0.03);
  }

  #eu-emblem {
    margin: 0;
  }

  #eu-emblem figcaption {
    display: none;
  }

</style>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=83e35b93" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/material.css?v=79c92029" />
    <script src="../../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="icon" href="../../../../_static/favicon.svg"/>
    <link rel="author" title="About these documents" href="../../../../about.html" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=indigo data-md-color-accent=blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#_modules/graphnet/models/gnn/dynedge" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../../index.html" title="graphnet  documentation"
           class="md-header-nav__button md-logo">
          
            &nbsp;
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">GraphNeT</span>
          <span class="md-header-nav__topic"> graphnet.models.gnn.dynedge </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../../../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder=""Search""
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/graphnet-team/graphnet/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GraphNeT
  </div>
</a>
          </div>
        </div>
      
      
  
  <script src="../../../../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "../../../../"versions.json"",
        target_loc = "../../../../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>
  

    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="../../../../index.html" class="md-tabs__link">Documentation</a></li>
          <li class="md-tabs__item"><a href="../../../index.html" class="md-tabs__link">Module code</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../../index.html" title="graphnet documentation" class="md-nav__button md-logo">
      
        <img src="../../../../_static/" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../../../index.html"
       title="graphnet documentation">GraphNeT</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/graphnet-team/graphnet/" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GraphNeT
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
    
      <a href="../../../../install.html" class="md-nav__link">Install</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../contribute.html" class="md-nav__link">Contribute</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../../api/graphnet.html" class="md-nav__link">API</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
  <ul class="md-nav__list" data-md-scrollfix="">
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <h1 id="modules-graphnet-models-gnn-dynedge--page-root">Source code for graphnet.models.gnn.dynedge</h1><div class="highlight"><pre>
<span></span><span class="sd">"""Implementation of the DynEdge GNN model architecture."""</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">LongTensor</span>
<span class="kn">from</span> <span class="nn">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Data</span>
<span class="kn">from</span> <span class="nn">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter_max</span><span class="p">,</span> <span class="n">scatter_mean</span><span class="p">,</span> <span class="n">scatter_min</span><span class="p">,</span> <span class="n">scatter_sum</span>

<span class="kn">from</span> <span class="nn">graphnet.models.components.layers</span> <span class="kn">import</span> <span class="n">DynEdgeConv</span>
<span class="kn">from</span> <span class="nn">graphnet.models.gnn.gnn</span> <span class="kn">import</span> <span class="n">GNN</span>
<span class="kn">from</span> <span class="nn">graphnet.models.utils</span> <span class="kn">import</span> <span class="n">calculate_xyzt_homophily</span>

<span class="n">GLOBAL_POOLINGS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"min"</span><span class="p">:</span> <span class="n">scatter_min</span><span class="p">,</span>
    <span class="s2">"max"</span><span class="p">:</span> <span class="n">scatter_max</span><span class="p">,</span>
    <span class="s2">"sum"</span><span class="p">:</span> <span class="n">scatter_sum</span><span class="p">,</span>
    <span class="s2">"mean"</span><span class="p">:</span> <span class="n">scatter_mean</span><span class="p">,</span>
<span class="p">}</span>


<div class="viewcode-block" id="DynEdge">
<a class="viewcode-back" href="../../../../api/graphnet.models.gnn.dynedge.html#graphnet.models.gnn.dynedge.DynEdge">[docs]</a>
<span class="k">class</span> <span class="nc">DynEdge</span><span class="p">(</span><span class="n">GNN</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""DynEdge (dynamical edge convolutional) model."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nb_inputs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">nb_neighbours</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="n">features_subset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">slice</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dynedge_layer_sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">post_processing_layer_sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">readout_layer_sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">global_pooling_schemes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">add_global_variables_after_pooling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">"""Construct `DynEdge`.</span>

<span class="sd">        Args:</span>
<span class="sd">            nb_inputs: Number of input features on each node.</span>
<span class="sd">            nb_neighbours: Number of neighbours to used in the k-nearest</span>
<span class="sd">                neighbour clustering which is performed after each (dynamical)</span>
<span class="sd">                edge convolution.</span>
<span class="sd">            features_subset: The subset of latent features on each node that</span>
<span class="sd">                are used as metric dimensions when performing the k-nearest</span>
<span class="sd">                neighbours clustering. Defaults to [0,1,2].</span>
<span class="sd">            dynedge_layer_sizes: The layer sizes, or latent feature dimenions,</span>
<span class="sd">                used in the `DynEdgeConv` layer. Each entry in</span>
<span class="sd">                `dynedge_layer_sizes` corresponds to a single `DynEdgeConv`</span>
<span class="sd">                layer; the integers in the corresponding tuple corresponds to</span>
<span class="sd">                the layer sizes in the multi-layer perceptron (MLP) that is</span>
<span class="sd">                applied within each `DynEdgeConv` layer. That is, a list of</span>
<span class="sd">                size-two tuples means that all `DynEdgeConv` layers contain a</span>
<span class="sd">                two-layer MLP.</span>
<span class="sd">                Defaults to [(128, 256), (336, 256), (336, 256), (336, 256)].</span>
<span class="sd">            post_processing_layer_sizes: Hidden layer sizes in the MLP</span>
<span class="sd">                following the skip-concatenation of the outputs of each</span>
<span class="sd">                `DynEdgeConv` layer. Defaults to [336, 256].</span>
<span class="sd">            readout_layer_sizes: Hidden layer sizes in the MLP following the</span>
<span class="sd">                post-processing _and_ optional global pooling. As this is the</span>
<span class="sd">                last layer(s) in the model, the last layer in the read-out</span>
<span class="sd">                yields the output of the `DynEdge` model. Defaults to [128,].</span>
<span class="sd">            global_pooling_schemes: The list global pooling schemes to use.</span>
<span class="sd">                Options are: "min", "max", "mean", and "sum".</span>
<span class="sd">            add_global_variables_after_pooling: Whether to add global variables</span>
<span class="sd">                after global pooling. The alternative is to  added (distribute)</span>
<span class="sd">                them to the individual nodes before any convolutional</span>
<span class="sd">                operations.</span>
<span class="sd">        """</span>
        <span class="c1"># Latent feature subset for computing nearest neighbours in DynEdge.</span>
        <span class="k">if</span> <span class="n">features_subset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">features_subset</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

        <span class="c1"># DynEdge layer sizes</span>
        <span class="k">if</span> <span class="n">dynedge_layer_sizes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dynedge_layer_sizes</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">(</span>
                    <span class="mi">128</span><span class="p">,</span>
                    <span class="mi">256</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="p">(</span>
                    <span class="mi">336</span><span class="p">,</span>
                    <span class="mi">256</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="p">(</span>
                    <span class="mi">336</span><span class="p">,</span>
                    <span class="mi">256</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="p">(</span>
                    <span class="mi">336</span><span class="p">,</span>
                    <span class="mi">256</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">]</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dynedge_layer_sizes</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">dynedge_layer_sizes</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">for</span> <span class="n">sizes</span> <span class="ow">in</span> <span class="n">dynedge_layer_sizes</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">sizes</span> <span class="ow">in</span> <span class="n">dynedge_layer_sizes</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">all</span><span class="p">(</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">)</span> <span class="k">for</span> <span class="n">sizes</span> <span class="ow">in</span> <span class="n">dynedge_layer_sizes</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_dynedge_layer_sizes</span> <span class="o">=</span> <span class="n">dynedge_layer_sizes</span>

        <span class="c1"># Post-processing layer sizes</span>
        <span class="k">if</span> <span class="n">post_processing_layer_sizes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">post_processing_layer_sizes</span> <span class="o">=</span> <span class="p">[</span>
                <span class="mi">336</span><span class="p">,</span>
                <span class="mi">256</span><span class="p">,</span>
            <span class="p">]</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">post_processing_layer_sizes</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">post_processing_layer_sizes</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">post_processing_layer_sizes</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_post_processing_layer_sizes</span> <span class="o">=</span> <span class="n">post_processing_layer_sizes</span>

        <span class="c1"># Read-out layer sizes</span>
        <span class="k">if</span> <span class="n">readout_layer_sizes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">readout_layer_sizes</span> <span class="o">=</span> <span class="p">[</span>
                <span class="mi">128</span><span class="p">,</span>
            <span class="p">]</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">readout_layer_sizes</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">readout_layer_sizes</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">readout_layer_sizes</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_readout_layer_sizes</span> <span class="o">=</span> <span class="n">readout_layer_sizes</span>

        <span class="c1"># Global pooling scheme(s)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">global_pooling_schemes</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">global_pooling_schemes</span> <span class="o">=</span> <span class="p">[</span><span class="n">global_pooling_schemes</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">global_pooling_schemes</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">pooling_scheme</span> <span class="ow">in</span> <span class="n">global_pooling_schemes</span><span class="p">:</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="n">pooling_scheme</span> <span class="ow">in</span> <span class="n">GLOBAL_POOLINGS</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">"Global pooling scheme </span><span class="si">{</span><span class="n">pooling_scheme</span><span class="si">}</span><span class="s2"> not supported."</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">global_pooling_schemes</span> <span class="ow">is</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_global_pooling_schemes</span> <span class="o">=</span> <span class="n">global_pooling_schemes</span>

        <span class="k">if</span> <span class="n">add_global_variables_after_pooling</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_pooling_schemes</span><span class="p">,</span> <span class="p">(</span>
                <span class="s2">"No global pooling schemes were request, so cannot add global"</span>
                <span class="s2">" variables after pooling."</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_add_global_variables_after_pooling</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">add_global_variables_after_pooling</span>
        <span class="p">)</span>

        <span class="c1"># Base class constructor</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">nb_inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_readout_layer_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># Remaining member variables()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_nb_inputs</span> <span class="o">=</span> <span class="n">nb_inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_nb_global_variables</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">+</span> <span class="n">nb_inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_nb_neighbours</span> <span class="o">=</span> <span class="n">nb_neighbours</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_features_subset</span> <span class="o">=</span> <span class="n">features_subset</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_construct_layers</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_construct_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Construct layers (torch.nn.Modules)."""</span>
        <span class="c1"># Convolutional operations</span>
        <span class="n">nb_input_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nb_inputs</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_global_variables_after_pooling</span><span class="p">:</span>
            <span class="n">nb_input_features</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nb_global_variables</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_conv_layers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="n">nb_latent_features</span> <span class="o">=</span> <span class="n">nb_input_features</span>
        <span class="k">for</span> <span class="n">sizes</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dynedge_layer_sizes</span><span class="p">:</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb_latent_features</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">ix</span><span class="p">,</span> <span class="p">(</span><span class="n">nb_in</span><span class="p">,</span> <span class="n">nb_out</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="n">ix</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">nb_in</span> <span class="o">*=</span> <span class="mi">2</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nb_in</span><span class="p">,</span> <span class="n">nb_out</span><span class="p">))</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_activation</span><span class="p">)</span>

            <span class="n">conv_layer</span> <span class="o">=</span> <span class="n">DynEdgeConv</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">),</span>
                <span class="n">aggr</span><span class="o">=</span><span class="s2">"add"</span><span class="p">,</span>
                <span class="n">nb_neighbors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_nb_neighbours</span><span class="p">,</span>
                <span class="n">features_subset</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_features_subset</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_conv_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv_layer</span><span class="p">)</span>

            <span class="n">nb_latent_features</span> <span class="o">=</span> <span class="n">nb_out</span>

        <span class="c1"># Post-processing operations</span>
        <span class="n">nb_latent_features</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">sizes</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dynedge_layer_sizes</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">nb_input_features</span>
        <span class="p">)</span>

        <span class="n">post_processing_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb_latent_features</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_post_processing_layer_sizes</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">nb_in</span><span class="p">,</span> <span class="n">nb_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
            <span class="n">post_processing_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nb_in</span><span class="p">,</span> <span class="n">nb_out</span><span class="p">))</span>
            <span class="n">post_processing_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_activation</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_post_processing</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">post_processing_layers</span><span class="p">)</span>

        <span class="c1"># Read-out operations</span>
        <span class="n">nb_poolings</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_pooling_schemes</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_pooling_schemes</span>
            <span class="k">else</span> <span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">nb_latent_features</span> <span class="o">=</span> <span class="n">nb_out</span> <span class="o">*</span> <span class="n">nb_poolings</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_global_variables_after_pooling</span><span class="p">:</span>
            <span class="n">nb_latent_features</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nb_global_variables</span>

        <span class="n">readout_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb_latent_features</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_readout_layer_sizes</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">nb_in</span><span class="p">,</span> <span class="n">nb_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">layer_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
            <span class="n">readout_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nb_in</span><span class="p">,</span> <span class="n">nb_out</span><span class="p">))</span>
            <span class="n">readout_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_activation</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_readout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">readout_layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_global_pooling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">LongTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Perform global pooling."""</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_pooling_schemes</span>
        <span class="n">pooled</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pooling_scheme</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_pooling_schemes</span><span class="p">:</span>
            <span class="n">pooling_fn</span> <span class="o">=</span> <span class="n">GLOBAL_POOLINGS</span><span class="p">[</span><span class="n">pooling_scheme</span><span class="p">]</span>
            <span class="n">pooled_x</span> <span class="o">=</span> <span class="n">pooling_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pooled_x</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">pooled_x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># `scatter_{min,max}`, which return also an argument, vs.</span>
                <span class="c1"># `scatter_{mean,sum}`</span>
                <span class="n">pooled_x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pooled_x</span>
            <span class="n">pooled</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pooled_x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pooled</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_calculate_global_variables</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">edge_index</span><span class="p">:</span> <span class="n">LongTensor</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">LongTensor</span><span class="p">,</span>
        <span class="o">*</span><span class="n">additional_attributes</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Calculate global variables."""</span>
        <span class="c1"># Calculate homophily (scalar variables)</span>
        <span class="n">h_x</span><span class="p">,</span> <span class="n">h_y</span><span class="p">,</span> <span class="n">h_z</span><span class="p">,</span> <span class="n">h_t</span> <span class="o">=</span> <span class="n">calculate_xyzt_homophily</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>

        <span class="c1"># Calculate mean features</span>
        <span class="n">global_means</span> <span class="o">=</span> <span class="n">scatter_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Add global variables</span>
        <span class="n">global_variables</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">global_means</span><span class="p">,</span>
                <span class="n">h_x</span><span class="p">,</span>
                <span class="n">h_y</span><span class="p">,</span>
                <span class="n">h_z</span><span class="p">,</span>
                <span class="n">h_t</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="o">+</span> <span class="p">[</span><span class="n">attr</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="n">additional_attributes</span><span class="p">],</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">global_variables</span>

<div class="viewcode-block" id="DynEdge.forward">
<a class="viewcode-back" href="../../../../api/graphnet.models.gnn.dynedge.html#graphnet.models.gnn.dynedge.DynEdge.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Apply learnable forward pass."""</span>
        <span class="c1"># Convenience variables</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span>

        <span class="n">global_variables</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_global_variables</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span>
            <span class="n">edge_index</span><span class="p">,</span>
            <span class="n">batch</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">n_pulses</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Distribute global variables out to each node</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_global_variables_after_pooling</span><span class="p">:</span>
            <span class="n">distribute</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>

            <span class="n">global_variables_distributed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="n">distribute</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="o">*</span> <span class="n">global_variables</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">global_variables_distributed</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># DynEdge-convolutions</span>
        <span class="n">skip_connections</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">conv_layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_conv_layers</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
            <span class="n">skip_connections</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Skip-cat</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">skip_connections</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Post-processing</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_processing</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># (Optional) Global pooling</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_pooling_schemes</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_pooling</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_global_variables_after_pooling</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">x</span><span class="p">,</span>
                        <span class="n">global_variables</span><span class="p">,</span>
                    <span class="p">],</span>
                    <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># Read-out</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_readout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span></div>
</div>

</pre></div>

          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2021-2023, GraphNeT team.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>